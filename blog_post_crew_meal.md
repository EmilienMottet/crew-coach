---
title: "Du MITM au Design Agentique : Automatiser sa nutrition sportive avec Claude, n8n et Hexis"
date: 2025-12-28T10:00:00+01:00
draft: false
tags: ["AI Agents", "Reverse Engineering", "MCP", "n8n", "Python", "Automation", "LLM Optimization"]
categories: ["Engineering"]
description: "Comment j'ai contourn√© une API ferm√©e via une attaque Man-in-the-Middle pour construire une flotte d'agents IA autonomes, optimis√©s et s√©curis√©s."
---

L'automatisation de la nutrition sportive est le Graal de beaucoup d'athl√®tes amateurs. On veut la pr√©cision d'un nutritionniste sans la charge mentale.

Mon objectif √©tait simple : synchroniser mes entra√Ænements (Intervals.icu) avec mes besoins nutritionnels (Hexis) et g√©n√©rer des plans de repas automatiques. Le probl√®me ? **Hexis n'a pas d'API publique pour la cr√©ation de repas.**

Voici comment j'ai combin√© **Reverse Engineering**, **Man-in-the-Middle**, **Design Agentique Avanc√©**, **Meta-MCP** et **n8n** pour construire un syst√®me autonome et √©conomique.

## 1. Le Hack : Reverse Engineering & Man-in-the-Middle

Puisque la porte d'entr√©e √©tait ferm√©e, je suis pass√© par la fen√™tre. Pour automatiser l'enregistrement des repas dans Hexis, j'ai d√ª comprendre comment leur application mobile communiquait avec leur backend.

### L'approche MITM (Man-in-the-Middle)
J'ai configur√© un proxy pour intercepter le trafic HTTPS entre mon t√©l√©phone et les serveurs d'Hexis. En observant les requ√™tes lors de la cr√©ation d'un repas dans l'app, j'ai d√©couvert une structure de donn√©es complexe.

### La d√©couverte du `refCode`
L'API ne se contente pas d'un ID d'aliment. Elle utilise une base de donn√©es tierce (Passio) et exige un param√®tre sp√©cifique et non document√© : le `refCode`.

C'est une cha√Æne encod√©e en Base64 renvoy√©e lors de la recherche d'aliment, mais qui doit imp√©rativement √™tre renvoy√©e telle quelle lors de l'enregistrement du repas. Sans ce `refCode`, l'API renvoie une erreur 400 muette.

```json
// Ce que l'API attend r√©ellement (d√©couvert via MITM)
{
  "foodId": "12345",
  "quantity": 150,
  "unit": "g",
  "metaData": {
    "refCode": "Base64StringHiddenInSearchResult..." // Le s√©same !
  }
}
```

J'ai encapsul√© cette logique dans un **serveur MCP (Model Context Protocol)** personnalis√©. Cet outil agit comme une couche d'abstraction : il g√®re la recherche, extrait le `refCode` silencieusement, et formate la requ√™te pour Hexis, rendant l'op√©ration transparente pour mes agents IA.

## 2. Architecture Agentique : Le Pattern Supervisor/Executor/Reviewer

Une fois l'acc√®s aux donn√©es r√©solu, il fallait un "cerveau". J'utilise **CrewAI** avec des mod√®les LLM avanc√©s (Claude Opus/Sonnet).

Cependant, j'ai rencontr√© un probl√®me majeur : les mod√®les "Thinking" (qui raisonnent longuement) sont excellents pour la strat√©gie nutritionnelle, mais **hallucinent souvent les appels d'outils** (tool calling) ou √©chouent √† respecter les formats JSON stricts.

La solution ? Une architecture en trois tiers :

### Tier 1 : Le Superviseur (Cerveau)
*   **R√¥le** : Strat√©gie pure. Il con√ßoit le plan de repas id√©al en fonction des macros cibles.
*   **Mod√®le** : Mod√®le "Thinking" complexe (ex: Claude Opus).
*   **Contrainte** : Aucun acc√®s aux outils (pour √©viter les hallucinations).

### Tier 2 : L'Ex√©cuteur (Bras)
*   **R√¥le** : Interaction API. Il prend le plan du superviseur et cherche les ingr√©dients r√©els dans la base de donn√©es via MCP.
*   **Mod√®le** : Mod√®le rapide et "b√™te" (ex: GPT-4o-mini ou Haiku).
*   **Sp√©cificit√©** : `has_tools=True`. Il ne r√©fl√©chit pas, il ex√©cute.

### Tier 3 : Le R√©viseur (Contr√¥le Qualit√©)
*   **R√¥le** : V√©rification et Assemblage. Il recalcule les macros exactes avec du code Python (plus fiable que le calcul mental d'un LLM) et valide la coh√©rence.
*   **Mod√®le** : Interm√©diaire.

Tout ce petit monde communique via des sch√©mas **Pydantic** stricts, garantissant que la sortie de l'un correspond parfaitement √† l'entr√©e de l'autre.

## 3. Infrastructure MCP : S√©curit√© et Modularit√© avec Meta-MCP

G√©rer une flotte d'agents qui ont besoin d'acc√®s vari√©s (Strava, Intervals.icu, Hexis, M√©t√©o...) peut vite devenir un cauchemar de s√©curit√©. Je ne voulais pas que chaque agent ait acc√®s √† tous les outils.

J'utilise **Meta-MCP**, une couche d'abstraction qui me permet de :

1.  **Regrouper les outils par domaine** : Un serveur MCP pour le sport, un pour la nutrition, un pour la m√©t√©o.
2.  **S√©curiser les acc√®s** : Chaque agent ne re√ßoit que le sous-ensemble d'outils dont il a besoin via une cl√© API unique.
3.  **Standardiser l'interface** : Peu importe le service sous-jacent, mes agents voient une interface d'outils unifi√©e.

C'est cette couche qui permet √† mon "Ex√©cuteur Hexis" d'acc√©der aux outils de nutrition sans risquer de supprimer une activit√© sur Strava par erreur.

## 4. Optimisation des Co√ªts : L'IA √† prix malin

Lancer des agents autonomes 24/7 a un co√ªt, surtout avec des mod√®les performants. Pour √©viter une facture OpenAI/Anthropic astronomique, j'ai mis en place une strat√©gie agressive d'optimisation :

### Reverse Proxies & Mod√®les Alternatifs
Au lieu de taper directement chez les g√©ants de la tech, j'utilise des **Reverse Proxies** compatibles OpenAI.
*   **Solutions test√©es** : J'ai commenc√© avec [copilot-api](https://github.com/ericc-ch/copilot-api), puis **ccproxy**, pour finir avec [CLIProxyAPI](https://github.com/router-for-me/CLIProxyAPI).
*   **Mod√®les exotiques** : Mention honorable √† **DeepSeek** et **GLM-4.6 (via z.ai)** qui offrent des performances proches de GPT-4 pour une fraction du prix.
*   **Astuces** : L'utilisation de mod√®les "Coder" (comme Qwen-Coder) pour des t√¢ches de structure JSON est souvent plus efficace et moins ch√®re que les mod√®les g√©n√©ralistes.

### Rotation Automatique
Mon syst√®me g√®re une **cascade de mod√®les**. Si le mod√®le "Premium" (Claude 3.5 Sonnet) atteint son quota ou rate-limit, le syst√®me bascule automatiquement sur un mod√®le "Eco" (GPT-4o-mini ou GLM-4) pour terminer la t√¢che. C'est transparent pour l'utilisateur et √ßa sauve la production.

## 5. L'Orchestration avec n8n

Avoir des agents intelligents ne suffit pas, il faut les faire vivre dans le temps. C'est l√† qu'intervient **n8n**.

J'ai mis en place un workflow (`meal-planning-weekly`) qui tourne chaque dimanche soir :

1.  **R√©cup√©ration de la charge d'entra√Ænement** : Le workflow interroge Intervals.icu pour conna√Ætre mes s√©ances de la semaine √† venir.
2.  **Optimisation du planning** : Un script JS r√©organise mes cr√©neaux (ex: "Si grosse sortie v√©lo le samedi -> Repas riche en glucides le vendredi soir").
3.  **Appel Asynchrone vers l'IA** : n8n d√©clenche mon script Python CrewAI via un webhook HTTP.
4.  **Pattern Callback** : Comme la g√©n√©ration de repas prend du temps (plusieurs minutes de r√©flexion pour les agents), n8n ne reste pas bloqu√©. Il attend un "ping" de retour (callback) une fois que les agents ont fini leur travail.
5.  **Distribution** : Le r√©sultat final (liste de courses + menu) est envoy√© directement sur Telegram.

## Conclusion

Ce projet montre que les limitations des API ferm√©es ne sont que temporaires face √† un peu de reverse engineering.

En combinant la puissance brute d'analyse des **LLMs "Thinking"**, la fiabilit√© d'ex√©cution des **serveurs MCP**, et l'orchestration de **n8n**, on peut cr√©er des syst√®mes v√©ritablement autonomes qui ont un impact r√©el sur le quotidien.

Le code est disponible (partiellement) sur mon GitHub. La prochaine √©tape ? Automatiser la commande des courses via l'API d'un drive... mais √ßa, c'est une autre histoire de reverse engineering.

üëâ [Lien vers le repository GitHub du projet](https://github.com/EmilienMottet/crew-coach)
