# Configuration des Endpoints - R√©sum√©

## üìä Mod√®les Disponibles

### Endpoint `/copilot/v1`
**Support**: ‚úÖ Function Calling | ‚úÖ System Prompts

Mod√®les principaux:
- `gpt-5` - GPT-5 (400K context, 128K output)
- `gpt-5-mini` - GPT-5 mini (264K context, 64K output)
- `gpt-5-codex` - GPT-5 Codex Preview (400K context, 128K output)
- `gpt-4.1` - GPT-4.1 (128K context, 16K output)
- `gpt-4o` - GPT-4o (128K context, 16K output)
- `claude-sonnet-4.5` - Claude Sonnet 4.5 (144K context, 16K output)
- `claude-haiku-4.5` - Claude Haiku 4.5 (144K context, 16K output)
- `claude-sonnet-4` - Claude Sonnet 4 (216K context, 16K output)
- `claude-3.5-sonnet` - Claude 3.5 Sonnet (90K context, 8K output)
- `gemini-2.5-pro` - Gemini 2.5 Pro (128K context, 64K output)
- `grok-code-fast-1` - Grok Code Fast 1 (128K context, 64K output)

### Endpoint `/claude/v1`
**Support**: ‚úÖ Function Calling | ‚úÖ System Prompts

Mod√®les Claude uniquement:
- `claude-sonnet-4-5-20250929` - Claude Sonnet 4.5
- `claude-haiku-4-5-20251001` - Claude Haiku 4.5
- `claude-opus-4-1-20250805` - Claude Opus 4.1
- `claude-opus-4-20250514` - Claude Opus 4
- `claude-sonnet-4-20250514` - Claude Sonnet 4
- `claude-3-7-sonnet-20250219` - Claude 3.7 Sonnet
- `claude-3-5-sonnet-20241022` - Claude 3.5 Sonnet
- `claude-3-5-haiku-20241022` - Claude 3.5 Haiku
- Plus anciens mod√®les Claude 3

### Endpoint `/codex/v1`
**Support**: ‚úÖ Function Calling | ‚ö†Ô∏è System Prompts d√©sactiv√©s (merg√©s dans message user)

> **Note**: Le codex endpoint supporte bien les tools/MCP mais requiert que les system prompts
> soient retir√©s et fusionn√©s dans le message utilisateur. C'est une optimisation sp√©cifique
> √† cet endpoint pour la g√©n√©ration de code.

Tous les mod√®les de `/copilot/v1` sont disponibles.

## ‚úÖ Compatibilit√© avec CrewAI/MCP

### R√©sum√© des Tests
Tous les endpoints ont √©t√© test√©s avec `test_function_calling_endpoints.py`:

| Endpoint | Model | Function Calling | Result |
|----------|-------|------------------|--------|
| `/copilot/v1` | gpt-5-mini | ‚úÖ | Tool call detected |
| `/copilot/v1` | claude-sonnet-4.5 | ‚úÖ | Tool call detected |
| `/copilot/v1` | claude-haiku-4.5 | ‚úÖ | Tool call detected |
| `/codex/v1` | gpt-5 | ‚úÖ | Tool call detected |
| `/codex/v1` | claude-sonnet-4.5 | ‚úÖ | Tool call detected |

### Configuration Agents CrewAI

**Agents AVEC outils MCP** (Description, Music):
```bash
# Recommand√©: Copilot (plus de flexibilit√©)
OPENAI_DESCRIPTION_API_BASE=https://ccproxy.emottet.com/copilot/v1
OPENAI_DESCRIPTION_MODEL_NAME=claude-sonnet-4.5

OPENAI_MUSIC_API_BASE=https://ccproxy.emottet.com/copilot/v1
OPENAI_MUSIC_MODEL_NAME=claude-haiku-4.5

# Alternative: Codex (fonctionne aussi)
# OPENAI_MUSIC_API_BASE=https://ccproxy.emottet.com/codex/v1
# OPENAI_MUSIC_MODEL_NAME=gpt-5
```

**Agents SANS outils** (Privacy, Translation):
```bash
# Tous les endpoints fonctionnent
OPENAI_PRIVACY_API_BASE=https://ccproxy.emottet.com/copilot/v1
OPENAI_PRIVACY_MODEL_NAME=gpt-5-mini

OPENAI_TRANSLATION_API_BASE=https://ccproxy.emottet.com/copilot/v1
OPENAI_TRANSLATION_MODEL_NAME=gpt-5-mini
```

## üîß Changements Effectu√©s

### 1. Suppression des restrictions incorrectes
**Fichier**: `llm_provider_rotation.py`

```python
# AVANT (‚ùå FAUX)
TOOL_FREE_ENDPOINT_HINTS = ("codex",)  # Bloquait codex pour tools
TOOL_FREE_MODEL_HINTS = ("gpt-5",)     # Bloquait gpt-5 pour tools

# APR√àS (‚úÖ CORRECT)
TOOL_FREE_ENDPOINT_HINTS: tuple = ()   # Aucune restriction
TOOL_FREE_MODEL_HINTS: tuple = ()      # Tous les mod√®les supportent tools
```

### 2. Suppression de la validation dans crew.py
La validation qui rejetait codex pour les agents avec outils a √©t√© supprim√©e car
elle √©tait bas√©e sur une fausse hypoth√®se.

### 3. Conservation du mode sans system prompt pour codex
```python
# Codex n√©cessite toujours que les system prompts soient d√©sactiv√©s
PROMPTLESS_ENDPOINT_HINTS = ("codex",)
# Mais cela n'emp√™che PAS l'utilisation des tools !
```

## üìù Tests Disponibles

```bash
# Tester la compatibilit√© function calling
python test_function_calling_endpoints.py

# Tester Music Agent avec codex
python test_codex_music_tools.py

# Tester la gestion des system prompts
python -c "from llm_provider_rotation import _requires_promptless_mode; 
print(_requires_promptless_mode('https://ccproxy.emottet.com/codex/v1', 'gpt-5'))"
```

## üéØ R√©sultat Final

‚úÖ **Tous vos endpoints supportent les tools/MCP pour CrewAI**  
‚úÖ **Le Music Agent peut maintenant appeler les outils Spotify**  
‚úÖ **Plus de flexibilit√© dans le choix des providers**  
‚úÖ **Rotation de providers fonctionne correctement**

## ‚ö†Ô∏è Points d'Attention

1. **Rate Limits**: L'endpoint `/claude/v1` peut avoir des rate limits plus stricts
2. **System Prompts**: Codex les d√©sactive automatiquement (pas un probl√®me pour les tools)
3. **Co√ªts**: V√©rifier les tarifs de chaque endpoint/mod√®le pour optimisation

## üîó Documentation

- `FUNCTION_CALLING_FIX.md` - D√©tails de la correction effectu√©e
- `test_function_calling_endpoints.py` - Tests de compatibilit√© endpoints
- `test_codex_music_tools.py` - Tests Music Agent + codex
